{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_images(dataset, dataset_name):\n",
    "#***\n",
    "#Checks images for:\n",
    "#* being an array\n",
    "#* shape (28x28)\n",
    "#***\n",
    "    \n",
    "    invalid_count = 0 # Counter for invalid images\n",
    "    valid_count = 0 # Counter for valid images\n",
    "\n",
    "    for idx, image in enumerate(dataset):\n",
    "        # Check if the image is a NumPy array\n",
    "        if not isinstance(image, np.ndarray):\n",
    "            print(f\"{dataset_name} - Index {idx}: Not a valid image array\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        # Check shape (should be 28x28)\n",
    "        if image.shape != (28,28):\n",
    "            print(f\"{dataset_name} - Index {idx}: Incorrect shape {image.shape}\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        if not (image.dtype == np.unit8 and image.min() >= 0 and image.max <= 255):\n",
    "            print(f\"{dataset_name} - Index {idx}: Invalid pixel values (Min: {image.min()}, Max: {image.max()}\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        if np.isnan(image).any():\n",
    "            print(f\"{dataset_name} - Index {idx}: Contains NaN values\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        valid_count += 1\n",
    "    \n",
    "    print(f\"\\n{dataset_name}: {valid_count} valid images, {invalid_count} invalid images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Images...\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChecking Images...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m check_images(\u001b[43mX_train\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m check_images(X_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Checking Images...\\n\")\n",
    "check_images(X_train, \"Train\")\n",
    "check_images(X_test, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "                                    X_train,\n",
    "                                    y_train,\n",
    "                                    test_size= 0.2,\n",
    "                                    random_state=0\n",
    "                                    )\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape)\n",
    "print(\"* Validation set:\", X_val.shape, y_val.shape)\n",
    "print(\"* Test set:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq = pd.DataFrame(columns=['Set', 'Label', 'Frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(dataset, dataset_name):\n",
    "\n",
    "    global df_freq\n",
    "    unique, counts = np.unique(dataset, return_counts=True)\n",
    "    for label, frequency in zip(unique, counts):\n",
    "        df_freq = pd.concat([df_freq, pd.DataFrame([{'Set': dataset_name, 'Label': class_names[label], 'Frequency': frequency}])], ignore_index=True)\n",
    "        print(f\"* {dataset_name} - {class_names[label]}: {frequency} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_labels(y_train, \"Train\")\n",
    "count_labels(y_test, \"Test\")\n",
    "count_labels(y_val, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_Train.shape[0],X_Train.shape[1],X_Train.shape[2], 1)\n",
    "X_val = X_val.reshape(X_val.shape[0],X_val.shape[1],X_val.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2], 1)\n",
    "\n",
    "print(X_train.shape) # Expcted output: (48000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_val = X_val.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = 10\n",
    "y_train = to_categorical(y_train, num_classes=n_labels)\n",
    "y_val = to_categorical(y_val, num_classes=n_labels)\n",
    "y_test = to_categorical(y_test, num_classes=n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tf_model(input_shape,n_labels):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(filters=16, kenel_size(3,3),input_shape))\n",
    "    model.add()\n",
    "\n",
    "    model.add()\n",
    "    model.add()\n",
    "\n",
    "    model.add()\n",
    "\n",
    "    model.add()\n",
    "    model.add()\n",
    "\n",
    "    model.add()\n",
    "    model.add()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
